{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML+tiIeLgOe/M2xgJ/5doW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nnamaka/ML_specializations/blob/main/Computer_vision/face_Detection/faceRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MNJNem1DpR9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "_xb9XHGpPQ9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 opencv-python matplotlib\n",
        "!pip install wget"
      ],
      "metadata": {
        "id": "Y9UMtA96PW24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Dependencies"
      ],
      "metadata": {
        "id": "XQlJCBB_PkQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "GCaHsD09PuKX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorflow dependencies - Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "7SwEiaa8QDZW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Folder Structures\n"
      ],
      "metadata": {
        "id": "5Ht1qzKOVeN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "POS_PATH = os.path.join('data', 'positive')\n",
        "NEG_PATH = os.path.join('data', 'negative')\n",
        "ANC_PATH = os.path.join('data', 'anchor')"
      ],
      "metadata": {
        "id": "KDigIfCAFAl8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make the directories\n",
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)"
      ],
      "metadata": {
        "id": "mdmQcQdiFW9Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collect Positive and Anchors.   \n",
        "And preprocess them"
      ],
      "metadata": {
        "id": "xLDpuAVAzk4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \n",
        "My positive and anchor images were stored in my Google Drive."
      ],
      "metadata": {
        "id": "ZB0WKwLPFpGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u1usYtu6R7Pi",
        "outputId": "20708f1c-ceaf-44f9-a11c-9c6753db0a2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/TFOD images/face.tar.gz\" /content && cp \"/content/drive/MyDrive/TFOD images/anchor.tar.gz\" /content"
      ],
      "metadata": {
        "id": "Bu5ibPKfpDeS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "uncompressed data file of positive image"
      ],
      "metadata": {
        "id": "kLov-E8FC9tU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf face.tar.gz && tar -xzf anchor.tar.gz"
      ],
      "metadata": {
        "id": "2ymx8putOjKd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "resize and store positive and anchor images in data folder, in their appropriate folders."
      ],
      "metadata": {
        "id": "0Xfyod7byUqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width = 250\n",
        "height = 250\n",
        "dim = (width, height)\n"
      ],
      "metadata": {
        "id": "dqSn38DPyc67"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anch_pos = [\"/content/Anchor/\",\"/content/Myimages\"]\n",
        "\n",
        "for path in anch_pos:\n",
        "  for filename in os.listdir(path):\n",
        "    if filename.endswith('.jpg'):\n",
        "      try:\n",
        "        if 'Anchor' in path:\n",
        "          img = cv2.imread(\"/content/Anchor/\" + filename, cv2.IMREAD_UNCHANGED)\n",
        "          new_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "          cv2.imwrite(ANC_PATH + '/' + filename, new_img)\n",
        "\n",
        "        if 'Myimages' in path:\n",
        "          img = cv2.imread(\"/content/Myimages/\" + filename, cv2.IMREAD_UNCHANGED)\n",
        "          new_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "          cv2.imwrite(POS_PATH + '/' + filename, new_img)\n",
        "      except:\n",
        "        pass\n",
        "      "
      ],
      "metadata": {
        "id": "lSIYLsAZzvsz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augument all positive and anchor images to increase data size and possible expose the model to newer samples"
      ],
      "metadata": {
        "id": "6flaLa1gCn13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(img):\n",
        "  data = []\n",
        "  for i in range(15):\n",
        "    img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
        "    img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
        "    img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100), np.random.randint(100)))\n",
        "    img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "    img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "\n",
        "    data.append(img)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "r-_qRfliC5Bv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid"
      ],
      "metadata": {
        "id": "dotL6qELLvOQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [POS_PATH, ANC_PATH]\n",
        "\n",
        "for path in paths:\n",
        "  print(\"inside \" + path)\n",
        "  for file_name in os.listdir(os.path.join(path)):\n",
        "    img_path = os.path.join(path, file_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    augmented_images = augment(img) \n",
        "    \n",
        "    for image in augmented_images:\n",
        "        cv2.imwrite(os.path.join(path, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KBBtvhO-mv39",
        "outputId": "ac128bc6-285b-44f6-a901-8ab0eb92052f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside data/positive\n",
            "inside data/anchor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the no of positive and anchor images"
      ],
      "metadata": {
        "id": "p8IPDpxwoIt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths:\n",
        "  print(\"no of images in \" + path + \" : \", end=\"\")\n",
        "  a = 0\n",
        "  for image in os.listdir(os.path.join(path)):\n",
        "    if image.endswith('.jpg'):\n",
        "      a = a + 1\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VBWG2lEUoTiH",
        "outputId": "873643f1-069f-45b0-a87e-baa627affd0d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of images in data/positive : 480\n",
            "no of images in data/anchor : 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collect Negative Images"
      ],
      "metadata": {
        "id": "ia4tUZTCQjl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O wildImages.tar http://vis-www.cs.umass.edu/lfw/lfw.tgz"
      ],
      "metadata": {
        "id": "_jGoz1IXorPj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b857c3aa-e843-46a2-d2c3-ddac2530b8da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-23 21:40:04--  http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180566744 (172M) [application/x-gzip]\n",
            "Saving to: ‘wildImages.tar’\n",
            "\n",
            "wildImages.tar      100%[===================>] 172.20M  31.2MB/s    in 6.2s    \n",
            "\n",
            "2022-09-23 21:40:10 (28.0 MB/s) - ‘wildImages.tar’ saved [180566744/180566744]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Untar Labelled Faces in the wild Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "P-9fwnZBF-MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf wildImages.tar"
      ],
      "metadata": {
        "id": "6BxCyZaMmm5N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move ifw images to the negative folder image directory\n",
        "# a = 0\n",
        "# no_of_neg_img = 450\n",
        "for directory in os.listdir('lfw'):\n",
        "  for file in os.listdir(os.path.join('lfw', directory)):\n",
        "    # a = a + 1;\n",
        "\n",
        "    # if ( a == no_of_neg_img):\n",
        "    #   break\n",
        "\n",
        "    old_path = os.path.join('lfw', directory, file)\n",
        "    new_path = os.path.join(NEG_PATH, file)\n",
        "    os.replace(old_path, new_path)"
      ],
      "metadata": {
        "id": "IXbP-9PbnBwt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Preprocess Images"
      ],
      "metadata": {
        "id": "-Y4lrPAUGNMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get image directories"
      ],
      "metadata": {
        "id": "mkR8nI7eFXeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(450)\n",
        "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(450)\n",
        "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(450)\n"
      ],
      "metadata": {
        "id": "9SjbqqOeFatT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_test = anchor.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "BATz018fGkLg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir_test.next())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qZrkp049Gnaf",
        "outputId": "c8543621-a16e-45bd-fa95-6aaa909e70ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'data/anchor/IMG_20220920_152033_954.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing - Scale and Resize"
      ],
      "metadata": {
        "id": "ULIHARpMGshc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_Path):\n",
        "\n",
        "  byte_img = tf.io.read_file(file_Path)\n",
        "\n",
        "  img = tf.io.decode_jpeg(byte_img)\n",
        "\n",
        "  img = tf.image.resize(img, (100, 100))\n",
        "  img = img / 255.0\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "oD-UZll2GxgL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = preprocess('data/anchor/IMG_20220920_152033_954.jpg')\n"
      ],
      "metadata": {
        "id": "shtlEl0TKSwB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.numpy().max() \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3tcQ1_2wKS7e",
        "outputId": "854ca14e-2954-4ab1-8797-4a100fbac1a9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pw5VO30-KTzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}